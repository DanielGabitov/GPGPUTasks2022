
1) Проще реализовать первый вариант:  
*y[i]* не зависит от других элементов последовательности. Как следствие, его реализация хорошо ложится на GPU: каждый *i* поток должен прибавить свое *x[i]* значение в *y[i - 1]*, *y[i]*, *y[i + 1]*. 
Со второй последовательностью такой метод не сработает.

2) Выражение *get_local_size(1) * get_local_id(0)* всегда кратно 32. Значит, все зависит от *get_local_id(1)*. Размер *warp* равен 32, размер *work-group* - (32, 32) с обходом по оси x => на каждый варп будет загружаться по строчке потоки из рабочей группы. Значит *сode divergence* не произойдет.

3)  Ответы:
   1) Да, *coalesced*. Все 32 потока в *warp*'e читают элементы последовательно причем кол-во элементов 32, что ровно помещается в одну линейку кеша.
   2) Нет, не *coalesced*. Каждый поток читает данные с шагом *get_local_size(1)*, то есть 32. В итоге на warp придется загрузить 32 линейки кеша.
   3) Да, *coalesced*. Этот случай похож на пункт номер 1. В нем на каждый warp попадала *i*-ая строчка матрицы. Однако теперь элементы сдвинуты на 1. То есть одному *warp*-у необходимо две строчки матрицы => две линейки кеша.
